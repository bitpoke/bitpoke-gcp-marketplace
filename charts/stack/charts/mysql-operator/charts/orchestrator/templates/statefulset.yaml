apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ template "orchestrator.fullname" . }}
  labels:
    app: {{ template "orchestrator.fullname" . }}
    chart: "{{ .Chart.Name }}-{{ .Chart.Version }}"
    release: "{{ .Release.Name }}"
    heritage: "{{ .Release.Service }}"
spec:
  replicas: {{ .Values.replicas }}
  serviceName: {{ template "orchestrator.fullname" . }}-headless
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app: {{ template "orchestrator.fullname" . }}
  template:
    metadata:
      labels:
        app: {{ template "orchestrator.fullname" . }}
      annotations:
        checksum/config: {{ include (print $.Template.BasePath "/config.yaml") . | sha256sum }}
        checksum/secret: {{ include (print $.Template.BasePath "/secret.yaml") . | sha256sum }}
    spec:
      affinity:
        {{- if .Values.nodeAffinity }}
        nodeAffinity:
          {{ toYaml .Values.nodeAffinity | nindent 10 }}
        {{- end }}
        {{- if eq "hard" .Values.antiAffinity }}
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - topologyKey: kubernetes.io/hostname
            labelSelector:
              matchLabels:
                app: {{ template "orchestrator.fullname" . }}
        {{- else if eq "soft" .Values.antiAffinity }}
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          # strongly prefer to stay away from other orchestrators
          - weight: 100
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app: {{ template "orchestrator.fullname" . }}
        {{- end }}
      {{- if .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml .Values.nodeSelector | indent 8 | printf "\n%s" }}
      {{- end }}
      {{- if .Values.tolerations }}
      tolerations:
        {{- toYaml .Values.tolerations | indent 8 | printf "\n%s" }}
      {{- end }}
      containers:
        - name: orchestrator
          image: {{ .Values.image }}
          imagePullPolicy: {{ .Values.imagePullPolicy }}
          ports:
            - containerPort: 3000
              name: web
              protocol: TCP
            - containerPort: 10008
              name: raft
              protocol: TCP
          env:
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
          envFrom:
            - prefix: ORC_
              secretRef:
                name: {{ template "orchestrator.fullname" . }}
          volumeMounts:
            - name: data
              mountPath: /var/lib/orchestrator/
            - name: config
              mountPath: /templates/
          livenessProbe:
            timeoutSeconds: 10
            initialDelaySeconds: 200
            httpGet:
              path: /api/lb-check
              port: 3000
          # https://github.com/github/orchestrator/blob/master/docs/raft.md#proxy-healthy-raft-nodes
          readinessProbe:
            timeoutSeconds: 10
            httpGet:
              path: /api/raft-health
              port: 3000
          resources:
          {{- toYaml .Values.resources | indent 12 | printf "\n%s" }}
      volumes:
        - name: config
          configMap:
            name: {{ template "orchestrator.fullname" . }}
        {{- if not .Values.persistence.enabled }}
        - name: data
          emptyDir: {}
        {{- end }}
  {{- if .Values.persistence.enabled }}
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes: [ {{ .Values.persistence.accessMode }} ]
        resources:
          requests:
            storage: {{ .Values.persistence.size }}
      {{- if .Values.persistence.storageClass }}
      {{- if (eq "-" .Values.persistence.storageClass) }}
        storageClassName: ""
      {{- else }}
        storageClassName: "{{ .Values.persistence.storageClass }}"
      {{- end }}
      {{- end }}
  {{- end }}
